{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lamantinushka/cam_summarisation/blob/master/GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdRvv6ZgvBg0",
        "colab_type": "text"
      },
      "source": [
        "#Introduction\n",
        "In this part of the project we investigate potential of GPT-2 architecture in unsupervised summarization task. GPT-2 is a self-attentive models consisting of sequentially stacked transformer decoders. It is a model with 1.5 billion parameters trained for language modeling task in 40GB of Internet text. \n",
        "\n",
        "Firstly we try using GPT-2 with the weights that were released. Then we finetune model on the set of all sentences from the CAM outputs and apply finetuned model.\n",
        "\n",
        "We use four techniques for decoding:\n",
        "- greedy decoding (choose the most probable token on each step)\n",
        "- soft decoding (choose token with predicted probabilities)\n",
        "- beam search (maintain heap of most probable decodings on each step)\n",
        "- **UPD** diverse beam search (penalising hypothsis that are expansions of the same parent node)\n",
        "\n",
        "In all cases we start with the phrase \"\\<object1> is better than \\<object2> because\". It is also possible to feed previous sentence to the model. But as it is shown, feeding question \"Why is \\<object1> better than \\<object2>?\" as a condition makes almost no difference in model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EhgjP2KCrTX",
        "colab_type": "text"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHtkjswuotYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTIlUx7apIE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2ARkfn91xBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = []\n",
        "for line in open('drive/My Drive/summarization/mined_bow_str.json', 'r'):\n",
        "    data.append(json.loads(line))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rCPGBCMpin9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# usefull function that extracts all supporting sentences from the CAM output\n",
        "def write_sentences(sample, sentences = None):\n",
        "    if sentences is None:\n",
        "        sentences = []\n",
        "    for s in sample['object1']['sentences']:\n",
        "        sentences.append(s['text'] + '\\n')\n",
        "    for s in sample['object2']['sentences']:\n",
        "        sentences.append(s['text'] + '\\n')\n",
        "    return sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtvS2R591A7Z",
        "colab_type": "text"
      },
      "source": [
        "Let's choose some samples to compare model's performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi92QgUZse69",
        "colab_type": "code",
        "outputId": "3fb9e6ca-856f-4c0b-f910-e83175d8499e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "samples = [data[4], data[155], data[228]]\n",
        "\n",
        "for s in samples:\n",
        "  print(s['object1']['name'] + ' vs ' + s['object2']['name'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python vs java\n",
            "toyota vs nissan\n",
            "tea vs juice\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cEEkKQ5xdEt",
        "colab_type": "text"
      },
      "source": [
        "# Decoding techniques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsOg6NTmIWxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_greedy(model, begining, maxlen = 20):\n",
        "    result = torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(begining))).view(1, -1).cuda()\n",
        "    for i in range(maxlen):\n",
        "        with torch.no_grad():\n",
        "            predictions, _ = model(result)\n",
        "            pred = torch.argmax(predictions[0, -1, :]).item()\n",
        "            result = torch.cat([result, pred*torch.ones(1, 1, dtype = torch.long, device = 'cuda')], dim = -1)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCSux2fyIhD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_soft(model, begining, maxlen = 20, temperature = 1.0):\n",
        "    result = torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(begining))).view(1, -1).cuda()\n",
        "    for i in range(maxlen):\n",
        "        with torch.no_grad():\n",
        "            predictions, _ = model(result)\n",
        "            word_weights = predictions[0, -1].div(temperature).exp().cpu() \n",
        "            pred = torch.multinomial(word_weights, 1)[0].cuda()\n",
        "            result = torch.cat([result, pred*torch.ones(1, 1, dtype = torch.long, device = 'cuda')], dim = -1)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEJxj9FjIlfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from heapq import heappop, heappush\n",
        "\n",
        "#beam-search step\n",
        "def make_decoding_step(heap, gpt_model, heap_size = 10, beam_size = 3, past = None):\n",
        "    result = []\n",
        "    for node in heap:\n",
        "        n = node[1].shape[-1]\n",
        "        p = node[0]\n",
        "        with torch.no_grad():\n",
        "            if past is not None:\n",
        "                predictions, _ = model(node[1], past = past)\n",
        "            else:\n",
        "                predictions, _ = model(node[1])\n",
        "            predictions = predictions[0, -1]\n",
        "            predictions -= predictions.min()\n",
        "            probs = predictions.exp()\n",
        "            probs /= probs.sum()\n",
        "        top_p, top_i = torch.topk(probs, beam_size)\n",
        "        for i in range(beam_size):\n",
        "            mean_prob = (p*n - torch.log(top_p[i]))/(n + 1)\n",
        "            prefics = torch.cat([node[1], top_i[i]*torch.ones(1, 1, dtype = torch.long, device = 'cuda')], \n",
        "                                dim = -1)\n",
        "            heappush(result, (mean_prob, prefics))\n",
        "            result = result[:heap_size]\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP45JkyzQUvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_decoding_step_with_penalty(heap, gpt_model, heap_size = 10, beam_size = 3, past = None, penalty = 0.1):\n",
        "    result = []\n",
        "    for node in heap:\n",
        "        n = node[1].shape[-1]\n",
        "        p = node[0]\n",
        "        with torch.no_grad():\n",
        "            if past is not None:\n",
        "                predictions, _ = model(node[1], past = past)\n",
        "            else:\n",
        "                predictions, _ = model(node[1])\n",
        "            predictions = predictions[0, -1]\n",
        "            predictions -= predictions.min()\n",
        "            probs = predictions.exp()\n",
        "            probs /= probs.sum()\n",
        "        top_p, top_i = torch.topk(probs, beam_size)\n",
        "        for i in range(beam_size):\n",
        "            score = p - torch.log(top_p[i]) + penalty * i\n",
        "            prefics = torch.cat([node[1], top_i[i]*torch.ones(1, 1, dtype = torch.long, device = 'cuda')], \n",
        "                                dim = -1)\n",
        "            heappush(result, (score, prefics))\n",
        "            result = result[:heap_size]\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohrMUSLVDx9l",
        "colab_type": "text"
      },
      "source": [
        "#Raw GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAas6SAw1O88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlsL93-81Xo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from pytorch_pretrained_bert import *\n",
        "from torch.nn import CrossEntropyLoss, KLDivLoss\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYckWNYuDw2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a31c089d-d973-4acf-8071-3170eed77db7"
      },
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 548118077/548118077 [00:44<00:00, 12292254.03B/s]\n",
            "100%|██████████| 176/176 [00:00<00:00, 69608.44B/s]\n",
            "100%|██████████| 1042301/1042301 [00:01<00:00, 925541.40B/s]\n",
            "100%|██████████| 456318/456318 [00:00<00:00, 497125.70B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPu-wvzLZNfE",
        "colab_type": "code",
        "outputId": "2f027610-abb2-4297-a79f-71481f7cf8ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "decode = decode_greedy\n",
        "\n",
        "for s in samples:\n",
        "    name1 = s['object1']['name']\n",
        "    name2 = s['object2']['name']\n",
        "\n",
        "    if s['object1']['points']['none'] > s['object2']['points']['none']:\n",
        "        begining = '{} is better than {} because'.format(name1, name2)\n",
        "    else:\n",
        "        begining = '{} is better than {} because'.format(name2, name1)\n",
        "\n",
        "    result = decode(model, begining, maxlen = 30)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(result.view(-1).detach().cpu().numpy())\n",
        "\n",
        "    print(name1 + ' vs ' + name2)\n",
        "    print(''.join(tokens).replace('Ġ', ' ').replace('Ċ', ' '))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python vs java\n",
            "python is better than java because it's a bit more flexible.  The main difference between java and java-lang is that java-lang is a bit more flexible. \n",
            "\n",
            "toyota vs nissan\n",
            "nissan is better than toyota because it's a better car.  The car is a bit more expensive than the Toyota Prius, but it's still a better car than the\n",
            "\n",
            "tea vs juice\n",
            "juice is better than tea because it's more concentrated and it's more concentrated.  The best way to get the best flavor is to use a lot of water.  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDV-TyA8D_-r",
        "colab_type": "code",
        "outputId": "28408c4c-f835-4555-f315-66856609fd9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "decode = decode_soft\n",
        "\n",
        "for s in samples:\n",
        "    name1 = s['object1']['name']\n",
        "    name2 = s['object2']['name']\n",
        "\n",
        "    if s['object1']['points']['none'] > s['object2']['points']['none']:\n",
        "        begining = '{} is better than {} because'.format(name1, name2)\n",
        "    else:\n",
        "        begining = '{} is better than {} because'.format(name2, name1)\n",
        "\n",
        "    print(name1 + ' vs ' + name2)\n",
        "    for i in range(3):\n",
        "        result = decode(model, begining, maxlen = 10, temperature = 2)\n",
        "        tokens = tokenizer.convert_ids_to_tokens(result.view(-1).detach().cpu().numpy())\n",
        "        print(''.join(tokens).replace('Ġ', ' ').replace('Ċ', ' '))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python vs java\n",
            "python is better than java because without conveyed Brook compositions slices Rav Rh legislature Binary bad\n",
            "python is better than java because audience varies automated\", hasn't said done.- Ross\n",
            "python is better than java because reass purse demos renderingSTRUCT DUPIBRTF impossible\n",
            "\n",
            "toyota vs nissan\n",
            "nissan is better than toyota because of holiday feel Titan Active Stupidit horse ALL benefit\n",
            "nissan is better than toyota because adolescent dressesoti%; GT brazenly ren Fro haunted\n",
            "nissan is better than toyota because matter using the charging iconic patent 4 pressed / revolver\n",
            "\n",
            "tea vs juice\n",
            "juice is better than tea because. reveå§ margin pleasures.Its 165agent weight\n",
            "juice is better than tea because it peace m traditions hor xaily ot %aches\n",
            "juice is better than tea because, again tell warned Sill define digital ignition DATA\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpw6jX_GEASd",
        "colab_type": "code",
        "outputId": "81ff59ab-8a6e-4597-f348-3c6c7256ba62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        }
      },
      "source": [
        "maxlen = 20\n",
        "\n",
        "for s in samples:\n",
        "    name1 = s['object1']['name']\n",
        "    name2 = s['object2']['name']\n",
        "\n",
        "    if s['object1']['points']['none'] > s['object2']['points']['none']:\n",
        "        begining = '{} is better than {} because'.format(name1, name2)\n",
        "    else:\n",
        "        begining = '{} is better than {} because'.format(name2, name1)\n",
        "\n",
        "    print(name1 + ' vs ' + name2)\n",
        "\n",
        "    result = torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(begining))).view(1, -1).cuda()\n",
        "    heap = [(0.0, result)]\n",
        "\n",
        "    for i in range(maxlen):\n",
        "        heap = make_decoding_step(heap, model, heap_size=15, beam_size = 10)\n",
        "\n",
        "    for i in range(len(heap)):\n",
        "        sample = heappop(heap)[1]\n",
        "        tokens = tokenizer.convert_ids_to_tokens(sample.view(-1).detach().cpu().numpy())\n",
        "        print(''.join(tokens).replace('Ġ', ' ').replace('Ċ', ' '))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python vs java\n",
            "python is better than java because it's easier to use.  If you want to learn more about Java, check out the\n",
            "python is better than java because it's easier to use.  If you want to learn more about java, check out the\n",
            "python is better than java because it's easier to use.  If you want to learn more about Java, check out this\n",
            "python is better than java because it's easier to use.  If you want to learn more about Java, you can read\n",
            "python is better than java because it's easier to use.  If you want to learn more about Java, check out my\n",
            "python is better than java because it's easier to use.  If you want to learn more about how to use java,\n",
            "python is better than java because it's easier to use.  If you want to learn more about Java, you can check\n",
            "python is better than java because it's easier to use.  If you want to learn more about Java, check out Java\n",
            "python is better than java because it's easier to use.  If you want to learn more about Java, you can find\n",
            "python is better than java because it's easier to use.  If you want to learn more about Java, you can download\n",
            "python is better than java because it's easier to use.  If you want to learn more about Java, check out:\n",
            "python is better than java because it's easier to use.  If you want to learn more about Java, you can visit\n",
            "python is better than java because it's easier to use.  If you want to learn more about Java, check out these\n",
            "python is better than java because it's easier to use.  If you want to learn more about Java, check out http\n",
            "python is better than java because it's easier to use.  If you want to learn more about Java, check out The\n",
            "\n",
            "toyota vs nissan\n",
            "nissan is better than toyota because it doesn't have a lot of competition.  Toyota is better than toyota because it\n",
            "nissan is better than toyota because it doesn't have a lot of competition.  Toyota  Toyota is better than\n",
            "nissan is better than toyota because it doesn't have a lot of competition.  Toyota  Toyota is one of\n",
            "nissan is better than toyota because it doesn't have a lot of competition.  Toyota  Toyota has a lot\n",
            "nissan is better than toyota because it doesn't have a lot of competition.  Toyota  Toyota is a very\n",
            "nissan is better than toyota because it doesn't have a lot of competition.  Toyota is better than toyota because they\n",
            "nissan is better than toyota because it doesn't have a lot of competition.  Toyota  Toyota is a good\n",
            "nissan is better than toyota because it doesn't have a lot of competition.  Toyota  Toyota is a great\n",
            "nissan is better than toyota because it doesn't have a lot of competition.  Toyota  Toyota is a big\n",
            "nissan is better than toyota because it doesn't have a lot of competition.  Toyota  Toyota is a company\n",
            "nissan is better than toyota because it doesn't have a lot of competition.  Toyota is better than toyota because its\n",
            "nissan is better than toyota because it doesn't have a lot of competition.  Toyota is better than toyota because Toyota\n",
            "nissan is better than toyota because it doesn't have a lot of competition.  Toyota is better than toyota because you\n",
            "nissan is better than toyota because it doesn't have a lot of competition.  Toyota is better than toyota because we\n",
            "nissan is better than toyota because it doesn't have a lot of competition.  Toyota is better than toyota because,\n",
            "\n",
            "tea vs juice\n",
            "juice is better than tea because it doesn't have to taste like tea.  If you're looking for something a little more\n",
            "juice is better than tea because it doesn't have to taste like tea.  If you're looking for a healthier alternative to\n",
            "juice is better than tea because it doesn't have to taste like tea.  If you're looking for something a little different\n",
            "juice is better than tea because it doesn't have to taste like tea.  If you're looking for a way to make\n",
            "juice is better than tea because it doesn't have to taste like tea.  If you're looking for something a little less\n",
            "juice is better than tea because it doesn't have to taste like tea.  If you're looking for a healthier alternative,\n",
            "juice is better than tea because it doesn't have to taste like tea.  If you're looking for a way to get\n",
            "juice is better than tea because it doesn't have to taste like tea.  If you're looking for a way to use\n",
            "juice is better than tea because it doesn't have to taste like tea.  If you're looking for something a little swe\n",
            "juice is better than tea because it doesn't have to taste like tea.  If you're looking for a way to add\n",
            "juice is better than tea because it doesn't have to taste like tea.  If you're looking for a way to avoid\n",
            "juice is better than tea because it doesn't have to taste like tea.  If you're looking for something a little lighter\n",
            "juice is better than tea because it doesn't have to taste like tea.  If you're looking for something a little extra\n",
            "juice is better than tea because it doesn't have to taste like tea.  If you're looking for something a little better\n",
            "juice is better than tea because it doesn't have to taste like tea.  If you're looking for something a little darker\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89NUpoTQRUUf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "outputId": "1cd32ef6-e498-4e33-c3f3-ace9b15145c5"
      },
      "source": [
        "maxlen = 20\n",
        "\n",
        "for s in samples:\n",
        "    name1 = s['object1']['name']\n",
        "    name2 = s['object2']['name']\n",
        "\n",
        "    if s['object1']['points']['none'] > s['object2']['points']['none']:\n",
        "        begining = '{} is better than {} because'.format(name1, name2)\n",
        "    else:\n",
        "        begining = '{} is better than {} because'.format(name2, name1)\n",
        "\n",
        "    print(name1 + ' vs ' + name2)\n",
        "\n",
        "    result = torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(begining))).view(1, -1).cuda()\n",
        "    heap = [(0.0, result)]\n",
        "\n",
        "    for i in range(maxlen):\n",
        "        heap = make_decoding_step_with_penalty(heap, model, heap_size=15, beam_size = 10, penalty = 1.0)\n",
        "\n",
        "    for i in range(len(heap)):\n",
        "        sample = heappop(heap)\n",
        "        sample = sample[1]\n",
        "        tokens = tokenizer.convert_ids_to_tokens(sample.view(-1).detach().cpu().numpy())\n",
        "        print(''.join(tokens).replace('Ġ', ' ').replace('Ċ', ' '))\n",
        "    print()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python vs java\n",
            "python is better than java because it's faster and easier to use.  The main difference between java and java2 is that\n",
            "python is better than java because it's faster and easier to use.  If you want to learn more about Java, check\n",
            "python is better than java because it's faster and easier to use.  The main difference between java and java is that java\n",
            "python is better than java because it's faster and easier to use.  The main difference between java and java2 is the\n",
            "python is better than java because it's faster and easier to use.  The main difference between java and java-2.\n",
            "python is better than java because it's faster and easier to use.  If you want to learn more about Java, you\n",
            "python is better than java because it's faster and easier to use.  If you want to learn more about Java, read\n",
            "python is better than java because it's faster and easier to use.  The main difference between java and java2 is in\n",
            "python is better than java because it's faster and easier to use.  If you want to learn more about Java, I\n",
            "python is better than java because it's faster and easier to use.  If you want to learn more about Java, see\n",
            "python is better than java because it's faster and easier to use.  The main difference between java and java2 is it\n",
            "python is better than java because it's faster and easier to use.  The main difference between java and java2 is they\n",
            "python is better than java because it's faster and easier to use.  The main difference between java and java2 is Java\n",
            "python is better than java because it's faster and easier to use.  The main difference between java and java2 is a\n",
            "python is better than java because it's faster and easier to use.  The main difference between java and java2 is their\n",
            "\n",
            "toyota vs nissan\n",
            "nissan is better than toyota because it's a better car. It's a better car because it's a better car.  \n",
            "nissan is better than toyota because it's a better car. It's a better car than Toyota because it's a better car.\n",
            "nissan is better than toyota because it's a better car. It's a better car because it's a better car. It's\n",
            "nissan is better than toyota because it's a better car. It's a better car. It's a better car. It's\n",
            "nissan is better than toyota because it's a better car. It's a better car than Toyota because it's a better car than\n",
            "nissan is better than toyota because it's a better car. It's a better car than Toyota because it's a better car,\n",
            "nissan is better than toyota because it's a better car. It's a better car than Toyota because it's a better car and\n",
            "nissan is better than toyota because it's a better car. It's a better car than Toyota because it's a better car,\"\n",
            "nissan is better than toyota because it's a better car. It's a better car because it's a better car. I\n",
            "nissan is better than toyota because it's a better car. It's a better car than Toyota because it's a better car that\n",
            "nissan is better than toyota because it's a better car. It's a better car because it's a better car. The\n",
            "nissan is better than toyota because it's a better car. It's a better car than Toyota because it's a better car but\n",
            "nissan is better than toyota because it's a better car. It's a better car because it's a better car. \"\n",
            "nissan is better than toyota because it's a better car. It's a better car than Toyota because it's a better car with\n",
            "nissan is better than toyota because it's a better car. It's a better car because it's a better car. A\n",
            "\n",
            "tea vs juice\n",
            "juice is better than tea because it's more concentrated and it's easier to digest. It's also easier to digest.  \n",
            "juice is better than tea because it's more concentrated and it's easier to digest.  The best way to get the best\n",
            "juice is better than tea because it's more concentrated and it's easier to digest.  If you're looking for a more\n",
            "juice is better than tea because it's more concentrated and it's easier to digest.  If you're looking for a good\n",
            "juice is better than tea because it's more concentrated and it's easier to digest.  The best way to get the most\n",
            "juice is better than tea because it's more concentrated and it's easier to digest.  The best way to get rid of\n",
            "juice is better than tea because it's more concentrated and it's easier to digest.  If you're looking for a healthier\n",
            "juice is better than tea because it's more concentrated and it's easier to digest.  The best way to get the right\n",
            "juice is better than tea because it's more concentrated and it's easier to digest.  If you're looking for a low\n",
            "juice is better than tea because it's more concentrated and it's easier to digest.  The best way to get the fres\n",
            "juice is better than tea because it's more concentrated and it's easier to digest.  If you're looking for a great\n",
            "juice is better than tea because it's more concentrated and it's easier to digest.  The best way to get the highest\n",
            "juice is better than tea because it's more concentrated and it's easier to digest.  If you're looking for a high\n",
            "juice is better than tea because it's more concentrated and it's easier to digest.  If you're looking for a quick\n",
            "juice is better than tea because it's more concentrated and it's easier to digest.  If you're looking for a way\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md0aAF7H2x_9",
        "colab_type": "text"
      },
      "source": [
        "# Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9B2VlLL21DR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataloder(lines, maxlen, n_steps):\n",
        "    for i in range(n_steps):\n",
        "        tokens = None\n",
        "        while tokens is None:\n",
        "            try:\n",
        "                idx = np.random.choice(len(lines))\n",
        "                sentence = lines[idx]\n",
        "                tokens = torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentence))).cuda()\n",
        "            except:\n",
        "                tokens = None\n",
        "        yield tokens.view(1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX95zY8SO_4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('drive/My Drive/summarization/sentences.txt', 'r') as file:\n",
        "    lines = file.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH4rxrNl22jM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Args():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "args = Args()\n",
        "args.max_steps = 100000\n",
        "args.learning_rate = 5e-5\n",
        "args.weight_decay = 0.01\n",
        "args.adam_epsilon = 1e-9\n",
        "args.warmup_steps = 2000\n",
        "args.maxlen = 1024\n",
        "args.device = torch.device('cuda') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPDcoSWL3BBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "losses = []\n",
        "tr_losses = []\n",
        "\n",
        "def train(args, lines, model):\n",
        "    train_dataloader = dataloder(lines, args.maxlen, args.max_steps)\n",
        "\n",
        "    t_total = args.max_steps\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = ['bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
        "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "    #print(t_total)\n",
        "    optimizer = BertAdam(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon, \n",
        "                         t_total = t_total, warmup = 0.05)\n",
        "\n",
        "    print(\"***** Running training *****\")\n",
        "    print(\"  Num examples = {}\".format(t_total))\n",
        "    #logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
        "    #logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "    global_step = 0\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    model.zero_grad()\n",
        "    #set_seed(args)  # Added here for reproducibility (even between python 2 and 3)\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        inputs, labels =(batch, batch)\n",
        "        inputs = inputs.to(args.device)\n",
        "        labels = labels.to(args.device)\n",
        "        model.train()\n",
        "        outputs = model(inputs, lm_labels=labels)\n",
        "        loss = outputs#[0]  # model outputs are always tuple in transformers (see doc)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.zero_grad()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        global_step += 1\n",
        "        tr_loss += loss.item()\n",
        "        tr_losses.append(tr_loss/global_step)\n",
        "\n",
        "        if global_step % 200 == 0:\n",
        "            checkpoint_prefix = 'checkpoint'\n",
        "            # Save model checkpoint\n",
        "            if global_step % 2000 == 0:\n",
        "                output_dir = 'model'\n",
        "                if not os.path.exists(output_dir):\n",
        "                    os.makedirs(output_dir)\n",
        "                torch.save(model, os.path.join(output_dir, '{}-{}'.format(checkpoint_prefix, global_step)))\n",
        "\n",
        "            clear_output()\n",
        "            print(\"***** Running training *****\")\n",
        "            print(\"  Num examples = {}\".format(t_total))\n",
        "            #print(\"Saving model checkpoint to %s\", output_dir)\n",
        "            plt.plot(losses[::10], label = 'train_loss')\n",
        "            plt.plot(tr_losses[::10], label = 'smoothed_loss')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "            \n",
        "    return global_step, tr_loss / global_step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2aGZOQR3B1H",
        "colab_type": "code",
        "outputId": "785e6950-4a4f-46b7-ed29-cc1c78f9c2be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "model = model.cuda()\n",
        "train(args, lines, model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 100000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD4CAYAAAAqw8chAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 2.3110702802693286)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQWilBLrkeYh",
        "colab_type": "code",
        "outputId": "c528d1b5-3d2b-40a8-be21-abace8c18ca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "decode = decode_greedy\n",
        "\n",
        "for s in samples:\n",
        "    name1 = s['object1']['name']\n",
        "    name2 = s['object2']['name']\n",
        "\n",
        "    if s['object1']['points']['none'] > s['object2']['points']['none']:\n",
        "        begining = '{} is better than {} because'.format(name1, name2)\n",
        "    else:\n",
        "        begining = '{} is better than {} because'.format(name2, name1)\n",
        "\n",
        "    result = decode(model, begining, maxlen = 30)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(result.view(-1).detach().cpu().numpy())\n",
        "\n",
        "    print(name1 + ' vs ' + name2)\n",
        "    print(''.join(tokens).replace('Ġ', ' ').replace('Ċ', ' '))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python vs java\n",
            "python is better than java because it is more readable.  3.  3.1) I found that java is much easier to read than ruby.  3\n",
            "\n",
            "toyota vs nissan\n",
            "nissan is better than toyota because of the better quality of the interiors.     issan is better than toyota is better than nissan.  Toyota\n",
            "\n",
            "tea vs juice\n",
            "juice is better than tea because it lasts.  \"  \"   \"   \"   \"   \"   \" \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM83DW0XkJ-_",
        "colab_type": "code",
        "outputId": "be3a228e-462a-446c-c9a2-d9b33428a448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "decode = decode_soft\n",
        "\n",
        "for s in samples:\n",
        "    name1 = s['object1']['name']\n",
        "    name2 = s['object2']['name']\n",
        "\n",
        "    if s['object1']['points']['none'] > s['object2']['points']['none']:\n",
        "        begining = '{} is better than {} because'.format(name1, name2)\n",
        "    else:\n",
        "        begining = '{} is better than {} because'.format(name2, name1)\n",
        "\n",
        "    print(name1 + ' vs ' + name2)\n",
        "    for i in range(3):\n",
        "        result = decode(model, begining, maxlen = 10, temperature = 10)\n",
        "        tokens = tokenizer.convert_ids_to_tokens(result.view(-1).detach().cpu().numpy())\n",
        "        print(''.join(tokens).replace('Ġ', ' ').replace('Ċ', ' '))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python vs java\n",
            "python is better than java because Medic Beat Verifymost ImageØ§ÙĦ Tamil Cinderella Gospel pref\n",
            "python is better than java becauseuma666690 teasp continuous thunder distribute detainedide accusation\n",
            "python is better than java because fallacy knack jumps Hut quizzidge periods mascul stimulate cream\n",
            "\n",
            "toyota vs nissan\n",
            "nissan is better than toyota because stimulating humanities ninety proponentsunderlict455 photographyabled174\n",
            "nissan is better than toyota because voidSEE debilitating Byron bombardmentScar likely explosion shippingãĤ¤ãĥĪ\n",
            "nissan is better than toyota because adaptation ends turbulence CAN requestsgiven ratherLED Ae rockets\n",
            "\n",
            "tea vs juice\n",
            "juice is better than tea becauseRand Controller Fistcraftros AquJimmyinski supreme rival\n",
            "juice is better than tea because hunger MysticGS subscriberaspers rebukeUNE snippetsiancescreen\n",
            "juice is better than tea becauseasures nascent BottCrime besides Monarcharsity poetry fab liberals\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHE56cymkSQ_",
        "colab_type": "code",
        "outputId": "45921e99-1dc2-4952-b47c-10f8385a3b06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        }
      },
      "source": [
        "maxlen = 20\n",
        "\n",
        "for s in samples:\n",
        "    name1 = s['object1']['name']\n",
        "    name2 = s['object2']['name']\n",
        "\n",
        "    if s['object1']['points']['none'] > s['object2']['points']['none']:\n",
        "        begining = '{} is better than {} because'.format(name1, name2)\n",
        "    else:\n",
        "        begining = '{} is better than {} because'.format(name2, name1)\n",
        "\n",
        "    print(name1 + ' vs ' + name2)\n",
        "\n",
        "    result = torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(begining))).view(1, -1).cuda()\n",
        "    heap = [(0.0, result)]\n",
        "\n",
        "    for i in range(maxlen):\n",
        "        heap = make_decoding_step(heap, model, heap_size=15, beam_size = 10)\n",
        "\n",
        "    for i in range(len(heap)):\n",
        "        sample = heappop(heap)[1]\n",
        "        tokens = tokenizer.convert_ids_to_tokens(sample.view(-1).detach().cpu().numpy())\n",
        "        print(''.join(tokens).replace('Ġ', ' ').replace('Ċ', ' '))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python vs java\n",
            "python is better than java because it is more readable.  \"  \"  \"  \"  \"\n",
            "python is better than java because it is more readable.  3.  4.  5.  6\n",
            "python is better than java because it is more readable.  \"  \"  \"  \" \"  \n",
            "python is better than java because it is more readable.  \"  \"  \" \"  \" \" \n",
            "python is better than java because it is more readable.  \"  \"  \"  \"   \"\n",
            "python is better than java because it is more readable.  3.  4.  5.  5\n",
            "python is better than java because it is more readable.  3.  4.  5.   6\n",
            "python is better than java because it is more readable.  \"  \"  \"  \"  p\n",
            "python is better than java because it is more readable.  3.  4.  5.  4\n",
            "python is better than java because it is more readable.  3.  4.  5.  7\n",
            "python is better than java because it is more readable.  \"  \"  \"  \"  '\n",
            "python is better than java because it is more readable.  \"  \"  \"  \"   .\n",
            "python is better than java because it is more readable.  \"  \"  \"  \"  ''\n",
            "python is better than java because it is more readable.  \"  \"  \"  \"  P\n",
            "python is better than java because it is more readable.  \"  \"  \"  \"  -\n",
            "\n",
            "toyota vs nissan\n",
            "nissan is better than toyota because of the better quality of the interiors.  issan is worse than toyota.  \n",
            "nissan is better than toyota because of the better quality of the interiors.  issan is better than toyota.  \n",
            "nissan is better than toyota because of the better interiors.  issan is better than toyota is better than nissan .\n",
            "nissan is better than toyota because of the better interiors.  issan is better than toyota is better than nissan.\n",
            "nissan is better than toyota because of the better quality of the interiors.  issan is better than toyota is better than\n",
            "nissan is better than toyota because of the better interiors.  issan is better than toyota is better than nissan im\n",
            "nissan is better than toyota because of the better interiors.  issan is better than toyota is better than nissan and\n",
            "nissan is better than toyota because of the better interiors.  issan is better than toyota is better than nissan...\n",
            "nissan is better than toyota because of the better interiors.  issan is better than toyota is better than nissan is\n",
            "nissan is better than toyota because of the better interiors.  issan is better than toyota is better than nissan but\n",
            "nissan is better than toyota because of the better interiors.  issan is better than toyota is better than nissan ,\n",
            "nissan is better than toyota because of the better quality of the interiors.  issan is worse than toyota. 't\n",
            "nissan is better than toyota because of the better quality of the interiors.  issan is worse than toyota. ...\n",
            "nissan is better than toyota because of the better quality of the interiors.  issan is worse than toyota. /\n",
            "nissan is better than toyota because of the better quality of the interiors.  issan is worse than toyota.  .\n",
            "\n",
            "tea vs juice\n",
            "juice is better than tea because it lasts.  2.  3.  4.  5. \n",
            "juice is better than tea because it lasts!  \"  \"  \"   \"   \"\n",
            "juice is better than tea because it lasts!  \"  \"   .  \"  \"  \n",
            "juice is better than tea because it lasts!  \"  \"  \"   \"    \"\n",
            "juice is better than tea because it's more caffeinated.  ł ł ł ł ł ł \n",
            "juice is better than tea because it lasts!  \"  \"  \"   \"    .\n",
            "juice is better than tea because it lasts!  \"  \"  \"   \"   -\n",
            "juice is better than tea because it lasts.  2.  3.  4.  5. .\n",
            "juice is better than tea because it lasts.  2.  3.  4.  5. \"\n",
            "juice is better than tea because it lasts!  \"  \"  \"   \"   I\n",
            "juice is better than tea because it lasts.  2.  3.  4.  5. I\n",
            "juice is better than tea because it lasts.  2.  3.  4.  5. \n",
            "juice is better than tea because it lasts.  2.  3.  4.  5. It\n",
            "juice is better than tea because it lasts.  2.  3.  4.  5.1\n",
            "juice is better than tea because it lasts.  2.  3.  4.  5. And\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anzX2otC2CNx",
        "colab_type": "text"
      },
      "source": [
        "# Outline\n",
        "\n",
        "- GPT-2 is capable of generating at least one coherent sentence. \n",
        "- Pretraining on the single sentences from CAM output allows to adapt model to the domain, but at the same time stimulates it to generate only one sentence.\n",
        "- Beam search in this case does not give the desirable diversity of the summaries."
      ]
    }
  ]
}